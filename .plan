[keys]
======================
+ --> done
* --> dropped
- --> to-do
======================


+ prepare train-data => [left, right, top_seg, top_ipm] 
+ generate dataset.json
+ fix train.py
+ train trimmed model
+ convert / visualize top_seg file in rgb
* visualize models 
* migrate to recommended pytorch / vision version
+ fix bev_segmented dataset
+ convert bev_segmented to single channel 

* use 2 classes => void + canopy

+ fix GT seg-mask resolution across files
* why are there huge black patches in GT? 
+ why is segmented-bev not centered in GT? 
* fix num_workers for train_loader
- fix transpose=True for SegLoader
+ figure out the co-ordinate system

+ utility to generate bev frames to s3

+ visualise cropped-seg-masks-mono in rgb
+ eval on the trained model
+ generate square shaped top_seg train-data
- provision for multiple training log folders

======================
why is loss not dropping?
======================
+ scale cx, cy, fx, fy
- check fx vs fy scaling scaling
- camera baseline scaling
- disparity scaling
- handle image resizing effect on disparity
+ review segmentation loss function calculations
+ fix loss calculations
- improve loss calculations
- fix segmentation module
+ segmentation module output should be discrete
* changing disparity channel count in costvol calculations
- fix model image pre-processing step
+ flip GT seg-mask in z-direction
- importance of transpose



+ why is loss different (or decreasing faster) in distributed-training?

- stereo rectification 
+ z / y swap
- passing camera orientation
+ how can y-min be negative? 

* enable saving of intermediate epochs 
+ plot epoch loss
- decide on the the epoch count
+ increase batch size
- figure out learning rate stretegy -> [use crestereo]

======================
check segmentation [end to end]
======================

+ fix predicted mask dimensions (480 * 480)
- transpose
+ fix SegLoader
- fix pytorch version
+ check loss function 
- improve loss function
- [debug] check pid-output with unet output
- [debug] check with camera-intrinsics / baseline scaling
* regenerate GT data with less black / blue regions
* get rid of ground points in GT
+ check unet implementation
- toogle number of classes, 6 vs 5
- establish correspondance with eval files and dataset files
- add segmentation mask 
- add hidden points mask
- add visibility mask
- ignoring void labels
- check for degeneracy
+  weighted cross entropy loss
- plot GT class-wise distribution
+ model is getting stuck at local minima, need to tune learning rate
- add augmentation for minor classes
- add focal loss function
+ reduce mask size from 400 * 400 to 200 * 200
+ flip mask for z-inversion 
- introduce a priority collapsing mechanism
+ fix z vs 10-z 
- baseline scaling
+ train on smaller mask dimensions ( 5m * 5m)
- augment minor classes (increase contrast etc, see chat-gpt project)
- parametrize scale factor

======================
demo video
======================
- generate video eval script
- augment minor classes
- check metric accuracy
- plot stem points on a plot to check metric accuracy 

- z-indices out-of-bounds error while bev_pcd -> bev_png
- check mono --> rgb seg-mask conversion in evaluate_model.py
- generate 500 frames

+ enable multi-gpu training
* fix logs in distributed training script
* double check distributed-training script
* what exactly happens in distributed training? 
