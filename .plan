---------------------
- --> TO-DO
+ --> DONE 
* --> DROPPED  
---------------------


======================
initial set-up
======================
+ prepare train-data => [left, right, top_seg, top_ipm] 
+ generate dataset.json
+ fix train.py
+ train trimmed model
+ convert / visualize top_seg file in rgb
* visualize models 
* migrate to recommended pytorch / vision version
+ fix bev_segmented dataset
+ convert bev_segmented to single channel 

* use 2 classes => void + canopy

+ fix GT seg-mask resolution across files
* why are there huge black patches in GT? 
+ why is segmented-bev not centered in GT? 
* fix num_workers for train_loader
+ fix transpose=True for SegLoader
+ figure out the co-ordinate system

+ utility to generate bev frames to s3

+ visualise cropped-seg-masks-mono in rgb
+ eval on the trained model
+ generate square shaped top_seg train-data
* provision for multiple training log folders


======================
fix model input
======================
+ flip GT seg-mask in z-direction
+ z / y swap
+ how can y-min be negative? 
* generate 500 frames


======================
why is loss not dropping?
======================
+ scale cx, cy, fx, fy
+ review segmentation loss function calculations
+ fix loss calculations
+ fix segmentation module
+ segmentation module output should be discrete
* changing disparity channel count in costvol calculations
+ importance of transpose


======================
implement baseline model
======================
+ fix predicted mask dimensions (480 * 480)
+ transpose
+ fix SegLoader
* fix pytorch version
+ check loss function 
* [debug] check pid-output with unet output
- [debug] check with camera-intrinsics / baseline scaling
* regenerate GT data with less black / blue regions
* get rid of ground points in GT
+ check unet implementation
- toogle number of classes, 6 vs 5
- establish correspondance with eval files and dataset files
+ add segmentation mask 
- ignoring void labels
* check for degeneracy
+ model is getting stuck at local minima, need to tune learning rate
+ reduce mask size from 400 * 400 to 200 * 200
+ flip mask for z-inversion 
* introduce a priority collapsing mechanism
+ fix z vs 10-z 
+ train on smaller mask dimensions ( 5m * 5m)
* z-indices out-of-bounds error while bev_pcd -> bev_png
+ check mono --> rgb seg-mask conversion in evaluate_model.py



======================
demo video
======================
+ generate video eval script
* augment minor classes
+ check metric accuracy
+ plot stem points on a plot to check metric accuracy 
* refactoring



======================
tune training params
======================
* enable saving of intermediate epochs 
+ plot epoch loss
- decide on the the epoch count
+ increase batch size
- figure out learning rate stretegy -> [use crestereo]
- tune learning rate (refer crestereo)


======================
enable distributed training
======================
+ enable multi-gpu training
* fix logs in distributed training script
* double check distributed-training script
* what exactly happens in distributed training? 
+ why is loss different (or decreasing faster) in distributed-training?


======================
aws based bev-generator
======================
+ start aws based data-generation pipeline
+ index to track processed files
- ipm rgb 
- occlusion mask
+ add index.json

======================
improve model baseline
======================
- fix black patches
- convert black to naviagble spaces
- add visibility mask
- refactoring
- parametrize intrinsics scaling factor
- move mavis.yaml to config
- add test.yaml, train.yaml and eval.yaml

- stereo rectification 
- add augmentation for minor classes
- add hidden points mask
- passing camera orientation

- fix model image pre-processing step

- add focal loss function
- plot GT class-wise distribution
- improve loss function
- tune weighted cross entropy loss
- change z-min to 0.5 in GT-seg-mask


======================
camera intrinsics scaling
======================
- write comparison script
- establish camera intrinsics scaling params
- camera baseline scaling
- check fx vs fy scaling
- disparity scaling
- handle image resizing effect on disparity


======================
data augmentation
======================
- increase contrast for minor classes
- fill void with ground points


======================
testing infrastructure
======================
- figure out metrics
- write testing class
- figure out eval-results logging mechanism 
- segmenent input data by class
- introduce seeding mechanism
- fix eval-video.py
- fix eval-model.py
- check sbevnet utils
- EvalClass 
- integrate eval cases
- metrics ?
- train / eval / test split
- processing bev-aws to bev-model pipeline
- utility to classify dataset into [object / pole / vineyard ] heavy


======================
test cases
======================
- w/o occlusion-mask.py
- w/o stereo-rectification 
- w/o ipm rgb
- w/o ipm features
- w/o data augmentation

- plot  measure accuracy
- plot train / val / test accuracy
- run on 500 / 200 / 200
- uplaod sample dataset to git


======================
data-generator.py
======================
+ split bev-dataset into train-val-test
* rename sbevnet module to model
+ flip masks
* support for extra data-fields
- resume training
* parametrize randomness / seeding
+ clean GT-dataset -> remove incomplete leaf folders
* generate gt data from z = 0.5 meters instead of z = 0m
- integrate generate_json